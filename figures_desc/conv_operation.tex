\begin{document}
The picture exposes the computation of a single element of 2D convolution. 
This is, in fact, a sum of elementwise multiplied matrices, except that one of the matrices is 
flipped so that the first element becomes the last. For instance, if we perform convolution on two 
$(N \times N)$ matrices, the element $(0, 0)$ will be multiplied by $(N, N)$ and vise versa. 
If one of the matrices is symmetrical in both axes, there is no need to flip either matrix.
\end{document}